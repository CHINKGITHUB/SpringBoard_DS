{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                  Detecting Malaria cells using Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  os\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img,img_to_array,load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "import cvutils\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import BatchNormalization\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Image Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data    = []\n",
    "labels  = []\n",
    "Parasitized  = os.listdir(\"cell_images/Parasitized/\")\n",
    "Uninfected   = os.listdir(\"cell_images/Uninfected/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in Parasitized:\n",
    "    if i != \"Thumbs.db\":\n",
    "        image = cv2.imread(\"cell_images/Parasitized/\" + i)\n",
    "        size_image = cv2.resize(image, (50, 50))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(1)\n",
    "for j in Uninfected:\n",
    "    if j != \"Thumbs.db\":\n",
    "        image = cv2.imread(\"cell_images/Uninfected/\" + j)\n",
    "        size_image = cv2.resize(image, (50, 50))\n",
    "        data.append(np.array(size_image))\n",
    "        labels.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save('Cells' , cells)\n",
    "np.save('Labels' , labels)\n",
    "\n",
    "idx = np.arange(cells.shape[0])\n",
    "np.random.shuffle(idx)\n",
    "cells = cells[idx]\n",
    "labels = labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1 , figsize = (15 , 9))\n",
    "n = 0 \n",
    "for i in range(49):\n",
    "    n += 1 \n",
    "    r = np.random.randint(0 , cells.shape[0] , 1)\n",
    "    plt.subplot(7 , 7 , n)\n",
    "    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n",
    "    plt.imshow(cells[r[0]])\n",
    "    plt.title('{} : {}'.format('Infected' if labels[r[0]] == 1 else 'UnInfected' ,\n",
    "                               labels[r[0]]) )\n",
    "    plt.xticks([]) , plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalize data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to 80% train and 20% test\n",
    "x_train, x_test, y_train, y_test = train_test_split(cells, labels, test_size = 0.2, random_state = 101) \n",
    "#split train data into validation data and train (70% train, 10% validation, 20% test)\n",
    "#x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state = 1)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "x_val   = x_val.astype('float32')\n",
    "x_train/255\n",
    "x_test/255\n",
    "x_val/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train,2)\n",
    "y_test  = keras.utils.to_categorical(y_test,2)\n",
    "y_val  = keras.utils.to_categorical(y_val,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a model and add layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32,kernel_size = (3,3),padding = 'same',input_shape = (50,50,3),activation = \"relu\"))\n",
    "#model.add(Conv2D(32,kernel_size = (3,3),activation = \"relu\")) #k\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(BatchNormalization(axis = -1))\n",
    "#model.add(Dropout(0.25))  # activated now\n",
    "\n",
    "\n",
    "model.add(Conv2D(64,kernel_size = (3,3),padding = 'same',activation = \"relu\"))\n",
    "#model.add(Conv2D(64,kernel_size = (3,3),activation = \"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(BatchNormalization(axis = -1))\n",
    "#model.add(Dropout(0.25)) \n",
    "\n",
    "\n",
    "#model.add(Conv2D(64,kernel_size = (3,3),padding = 'same',activation = \"relu\"))\n",
    "#model.add(Conv2D(64,kernel_size = (3,3),activation = \"relu\"))\n",
    "#model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(BatchNormalization(axis = -1))\n",
    "#model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(110, activation = \"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(2,activation = \"softmax\"))\n",
    "\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "                loss= 'categorical_crossentropy',\n",
    "                optimizer= \"adam\",\n",
    "                metrics= ['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(\n",
    "            x_train,\n",
    "            y_train,\n",
    "            batch_size= 50,\n",
    "            epochs= 5,\n",
    "            validation_data= (x_val,y_val),\n",
    "            shuffle= True\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "acc = pd.DataFrame.from_dict(hist.history)\n",
    "acc = pd.concat([pd.Series(range(0,30),name='epochs'),acc],axis=1)\n",
    "acc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(hist.history['acc'])\n",
    "plt.plot(hist.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save neural network structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Struct = model.to_json()\n",
    "file_name = Path(\"model_structure.json\")\n",
    "file_name.write_text(model_Struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save neural network's trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypredict = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ypredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating the model by passing single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Uninfected\",\"Infected\"]\n",
    "from keras.preprocessing import image\n",
    "#img = image.load_img(\"cell_images/Parasitized/C37BP2_thinF_IMG_20150620_131423a_cell_92.png\", target_size=(50, 50))\n",
    "img = image.load_img(\"cell_images/Uninfected/C1_thinF_IMG_20150604_104722_cell_123.png\", target_size=(50, 50))\n",
    "image_to_test = image.img_to_array(img)\n",
    "list_of_images = np.expand_dims(image_to_test, axis=0)\n",
    "results = model.predict(list_of_images)\n",
    "single_result = results[0]\n",
    "most_likely_class_index = int(np.argmax(single_result))\n",
    "class_likelihood = single_result[most_likely_class_index]\n",
    "#print(most_likely_class_index)\n",
    "class_label = class_labels[most_likely_class_index]\n",
    "img\n",
    "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Validating the model by loading model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Uninfected\",\"Infected\"]\n",
    "\n",
    "# Load the json file that contains the model's structure\n",
    "f = Path(\"model_Structure.json\")\n",
    "model_Structure = f.read_text()\n",
    "\n",
    "# Recreate the Keras model object from the json data\n",
    "model = model_from_json(model_Structure)\n",
    "\n",
    "# Re-load the model's trained weights\n",
    "model.load_weights(\"model_weights.h5\")\n",
    "\n",
    "# Load an image file to test, resizing it to 32x32 pixels (as required by this model)\n",
    "img = image.load_img(\"cell_images/Parasitized/C38P3thinF_original_IMG_20150621_112116_cell_204.png\", target_size = (50,50))\n",
    "#img = image.load_img(\"cell_images/Uninfected/C1_thinF_IMG_20150604_104722_cell_123.png\", target_size = (50,50))\n",
    "# Convert the image to a numpy array\n",
    "img_to_test = image.img_to_array(img)\n",
    "\n",
    "# Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\n",
    "list_of_images = np.expand_dims(img_to_test,axis= 0)\n",
    "\n",
    "# Make a prediction using the model\n",
    "results = model.predict(list_of_images)\n",
    "\n",
    "# Since we are only testing one image, we only need to check the first result\n",
    "single_result = results[0]\n",
    "# We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\n",
    "most_likely_class_indx = int(np.argmax(single_result))\n",
    "class_likhood = single_result[most_likely_class_indx]\n",
    "\n",
    "\n",
    "# Get the name of the most likely class\n",
    "class_label = class_labels[most_likely_class_indx]\n",
    "\n",
    "# Print the result\n",
    "\n",
    "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likhood))\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Prediction using Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "from pathlib import Path\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "from keras.applications import vgg16\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = applications.VGG16(include_top= False, weights= 'imagenet')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = Path(\"model_structure.json\")\n",
    "model_struct_Pretrain = file_path.read_text()\n",
    "Model_pretrained = model_from_json(model_struct_Pretrain)\n",
    "Model_pretrained.load_weights(\"model_weights.h5\",by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = image.load_img(\"cell_images/Uninfected/C1_thinF_IMG_20150604_104722_cell_123.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_array_pre = image.img_to_array(img)\n",
    "images = np.expand_dims(img_array_pre, axis = 0)\n",
    "#images = vgg16.preprocess_input(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected input_2 to have shape (50, 50, 3) but got array with shape (100, 136, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ae67df703ddb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeature_extraction_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVGG16\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extraction_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Given the extracted features, make a final prediction using our own model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1816\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected input_2 to have shape (50, 50, 3) but got array with shape (100, 136, 3)"
     ]
    }
   ],
   "source": [
    "# Normalize the data\n",
    "images = vgg16.preprocess_input(images)\n",
    "\n",
    "# Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\n",
    "feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(50, 50, 3))\n",
    "features = feature_extraction_model.predict(images)\n",
    "\n",
    "# Given the extracted features, make a final prediction using our own model\n",
    "#results = model.predict(features)\n",
    "\n",
    "# Since we are only testing one image with possible class, we only need to check the first result's first element\n",
    "#single_result = results[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(\"Likelihood that this image contains a dog: {}%\".format(int(single_result * 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "\n",
    "base_model = VGG19(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('block4_pool').output)\n",
    "\n",
    "img_path = 'elephant.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "block4_pool_features = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from imagenet_utils import decode_predictions\n",
    "print('Predicted:', decode_predictions(block4_pool_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import imagenet_utils\n",
    "#from imagenet_utils import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_utils.decode_predictions(block4_pool_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model= vgg16.VGG16(include_top=False, weights=None,input_shape=(150,150,3), pooling='avg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.load_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
